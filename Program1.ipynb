{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Program1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORgSzqt0R11qAb9Ij8+WzN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amartyaveer/ChatterBotter_Task/blob/master/Program1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYWDF0DqtFJv"
      },
      "source": [
        "# Extracting noun form fetch_20newsgroups and storing data to Mongodb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUK-bxbjryk5"
      },
      "source": [
        "!pip install pymongo[srv]\n",
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.porter import *\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmg5YezGsXJE"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "fetch_20newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQxp17I72gO7",
        "outputId": "0d3ccdd9-3a3e-4880-8c73-e752b4750def"
      },
      "source": [
        "fetch_20newsgroups.keys()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZPw9fbK2v1R"
      },
      "source": [
        "data = pd.DataFrame([fetch_20newsgroups.data,[fetch_20newsgroups.target]]).T"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ukt2ost2v7e"
      },
      "source": [
        "data = data.drop(1, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryCVMRq221iL"
      },
      "source": [
        "text = \"\"\n",
        "for i in data[0]:\n",
        "    for j in i.split(\" \"):\n",
        "            text+=j+\" \""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpSdiUim252a"
      },
      "source": [
        "def review_to_words(review):\n",
        "    nltk.download([\"stopwords\", \"wordnet\"], quiet=True)\n",
        "    \n",
        "    text = BeautifulSoup(review, \"html.parser\").get_text() # Remove HTML tags\n",
        "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower()) # Convert to lower case\n",
        "    words = text.split() # Split string into words\n",
        "    noun_list = [i.name().split('.', 1)[0] for i in wn.all_synsets('n')]\n",
        "    words = [w for w in words if w  in noun_list] # selects noun\n",
        "\n",
        "    return words\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_bPQtFC29MW"
      },
      "source": [
        "words = review_to_words(text)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-AvECD-2-VU"
      },
      "source": [
        "noun_words=set()\n",
        "for i in words:\n",
        "  if(len(i) > 3):\n",
        "    noun_words.add(i)\n",
        "  \n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q57aTY6rI3_E"
      },
      "source": [
        "noun_word_dict = {}\n",
        "\n",
        "for i in range(len(noun_words)):\n",
        "    noun_word_dict[i] = (list(noun_words)[i])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGtAwzewJODO"
      },
      "source": [
        "cluster = MongoClient(\"mongodb+srv://Amartyaveer72:<password>@cluster0.qjtjq.mongodb.net/fetch_20newsgroups?retryWrites=true&w=majority\")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja3ycWPSJbGO"
      },
      "source": [
        "db = cluster['fetch_20newsgroups']\n",
        "collections = db['Noun']"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IttdSz2EJ8V9"
      },
      "source": [
        "for key, val in noun_word_dict.items():\n",
        "  collections.insert_one({\"_id\": key, \"name\": val})"
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}